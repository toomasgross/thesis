{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737d2272",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import seaborn as sns\n",
    "\n",
    "from matplotlib import pyplot\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6787df87",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2020 = pd.read_csv(\"C:/Users/Toomas/Desktop/ITMI_Data/Cleaned_datasets_25_64/Yearly/2020_cleaned_weights.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7022bb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns that are irrelevant for analysis\n",
    "\n",
    "df_2020 = df_2020.drop(columns=['survey_year', 'respondent_id', 'age','bmi','bmi_four_groups','bmi_two_groups_split30', 'weights'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ec2242",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dummy variables\n",
    "# first change values from numeric to nominal for readable dummy labels\n",
    "\n",
    "df_2020['gender'] = df_2020['gender'].replace([1,2],['MALE','FEMALE'])\n",
    "df_2020['age_group'] = df_2020['age_group'].replace([1,2,3,4],['25_34','35_44','45_54','55_64'])\n",
    "df_2020['ethnicity_estonian_nonestonian'] = df_2020['ethnicity_estonian_nonestonian'].replace([1,2],['ESTONIAN','NON_ESTONIAN'])\n",
    "df_2020['education'] = df_2020['education'].replace([1,2,3,4],['PRIMARY_BASIC','SECONARY','SECONDARY_VOCATIONAL','HIGHER'])\n",
    "df_2020['income_per_household_member'] = df_2020['income_per_household_member'].replace([1,2,3,4],['QUARTILE_1','QUARTILE_2','QUARTILE_3','QUARTILE_4'])\n",
    "df_2020['chronic_disease'] = df_2020['chronic_disease'].replace([1,2],['YES','NO'])\n",
    "df_2020['smoking_history'] = df_2020['smoking_history'].replace([1,2,3,4],['NEVER','FORMERLY','SELDOM','DAILY'])\n",
    "df_2020['alcohol_standard_units_consumption_frequency'] = df_2020['alcohol_standard_units_consumption_frequency'].replace([1,2,3,4,5],['NEVER','<1x_MONTH','1+x_MONTH','1x_WEEK','ALMOST_DAILY'])\n",
    "df_2020['exercising_frequency'] = df_2020['exercising_frequency'].replace([1,2,3,4,5,6],['NEVER','1x_MONTH','2_3x_MONTH','1x_WEEK','2_3x_WEEK', '4_7X_WEEK'])\n",
    "df_2020['work_physical_effort_level'] = df_2020['work_physical_effort_level'].replace([1,2,3,4],['LITTLE','SOME','AVERAGE','A_LOT'])\n",
    "\n",
    "\n",
    "df_dummies = pd.get_dummies(df_2020, columns=['gender', 'age_group', \\\n",
    "                                              'ethnicity_estonian_nonestonian', 'education',\\\n",
    "                                              'income_per_household_member', 'chronic_disease',\\\n",
    "                                              'smoking_history',\\\n",
    "                                              'alcohol_standard_units_consumption_frequency',\\\n",
    "                                              'exercising_frequency',\\\n",
    "                                              'work_physical_effort_level'],drop_first=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c09e539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print out names of columns\n",
    "\n",
    "df_dummies.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215298b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## correlation graph\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "plt.figure(figsize = (20,10))\n",
    "\n",
    "# get a color map\n",
    "\n",
    "my_cmap = cm.get_cmap('Accent')\n",
    "\n",
    "# Get correlation of bmi_two_groups_split25 with other variables\n",
    "\n",
    "df_dummies.corr()['bmi_two_groups_split25'].sort_values(ascending = False).plot(kind='bar', cmap=my_cmap)\n",
    "\n",
    "# set title for figure, and labels x and y axes \n",
    "\n",
    "plt.title('Correlation of bmi_two_groups_split25 with other features', fontsize=20)\n",
    "plt.xlabel('Feature', fontsize=20)\n",
    "plt.ylabel('BMI<25.0 or BMI≥25.0', fontsize=20)\n",
    "plt.xticks(fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "plt.show()\n",
    "plt.savefig(\"C:/Users/Toomas/Desktop/ITMI_Data/Tables and graphs/25_64/ML/correlations.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2610f85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling all variables to the range of 0 to 1 before data learning process\n",
    "\n",
    "y = df_dummies['bmi_two_groups_split25'].values\n",
    "X = df_dummies.drop(columns = ['bmi_two_groups_split25'])\n",
    "\n",
    "features = X.columns.values\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "scaler.fit(X)\n",
    "X = pd.DataFrame(scaler.transform(X))\n",
    "X.columns = features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c094d816",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data into training and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f326f979",
   "metadata": {},
   "outputs": [],
   "source": [
    "#====================================\n",
    "# Logistic regression model training\n",
    "#====================================\n",
    "\n",
    "model_LR = LogisticRegression(random_state=1)\n",
    "model_LR.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66eef29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print out the hyperparameters of the trained model\n",
    "model_LR.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3f5650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LR model prediction and metrics\n",
    "y_pred = model_LR.predict(X_test)\n",
    "\n",
    "print('LR model metrics:')\n",
    "print('Accuracy: {:.2f}'.format(accuracy_score(y_test, y_pred)))\n",
    "print('Precision: \\t {0:.2f}'.format(metrics.precision_score(y_test, y_pred)))\n",
    "print('Recall: \\t {0:.2f}'.format(metrics.recall_score(y_test, y_pred)))\n",
    "print('F1-score: \\t {0:.2f}'.format(metrics.f1_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2611d4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LR model performance with K-folds validation\n",
    "\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "model_LR_1 = LogisticRegression(random_state=1)\n",
    "scores1 = cross_val_score(model_LR_1, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "scores2 = cross_val_score(model_LR_1, X, y, scoring='precision', cv=cv, n_jobs=-1)\n",
    "scores3 = cross_val_score(model_LR_1, X, y, scoring='recall', cv=cv, n_jobs=-1)\n",
    "scores4 = cross_val_score(model_LR_1, X, y, scoring='f1', cv=cv, n_jobs=-1)\n",
    "scores5 = cross_val_score(model_LR_1, X, y, scoring='roc_auc', cv=cv, n_jobs=-1)\n",
    "\n",
    "print('Accuracy: %.2f' % (mean(scores1)))\n",
    "print('Precision: %.2f' % (mean(scores2)))\n",
    "print('Recall: %.2f' % (mean(scores3)))\n",
    "print('F1 Score: %.2f' % (mean(scores4)))\n",
    "print('AUC Score: %.2f' % (mean(scores5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad03821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get importance of features in LR model\n",
    "importance = model_LR.coef_[0]\n",
    "# summarize feature importance\n",
    "for i,v in enumerate(importance):\n",
    "    print('Feature: %0d, Score: %.5f' % (i,v))\n",
    "# plot feature importance\n",
    "pyplot.bar([x for x in range(len(importance))], importance)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19bab44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the weights of 10 most important variables affecting BMI≥25.0 in LR model \n",
    "\n",
    "weights = pd.Series(model_LR.coef_[0], index = X.columns.values)\n",
    "print(weights.sort_values(ascending=True)[-10:].plot(kind='bar', color='grey'))\n",
    "plt.title('LR (+)')\n",
    "plt.savefig(\"C:/Users/Toomas/Desktop/ITMI_Data/Tables and graphs/25_64/ML/LR_features_most_BMI25.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04a0deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the most negative impact / LR model\n",
    "print(weights.sort_values(ascending=False)[-10:].plot(kind='bar', color='grey'))\n",
    "plt.title('LR (-)')\n",
    "plt.savefig(\"C:/Users/Toomas/Desktop/ITMI_Data/Tables and graphs/25_64/ML/LR_features_least_BMI25.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feda088f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# roc curve for LR model\n",
    "\n",
    "pred_prob1 = model_LR.predict_proba(X_test)\n",
    "fpr1, tpr1, thresh1 = roc_curve(y_test, pred_prob1[:,1], pos_label=1)\n",
    "\n",
    "# roc curve for tpr = fpr \n",
    "random_probs = [0 for i in range(len(y_test))]\n",
    "p_fpr, p_tpr, _ = roc_curve(y_test, random_probs, pos_label=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8666fb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# computing auc score for LR\n",
    "auc_score1 = roc_auc_score(y_test, pred_prob1[:,1])\n",
    "print(auc_score1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00853ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn')\n",
    "\n",
    "# plot roc curves\n",
    "plt.plot(tpr1, fpr1, linestyle='--',color='orange', label='Logistic Regression')\n",
    "plt.plot(p_fpr, p_tpr, linestyle='--', color='blue')\n",
    "# title\n",
    "plt.title('ROC curve')\n",
    "# x label\n",
    "plt.xlabel('False Positive Rate')\n",
    "# y label\n",
    "plt.ylabel('True Positive Rate')\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.savefig(\"C:/Users/Toomas/Desktop/ITMI_Data/Tables and graphs/25_64/ML/ROC_curve_LR_BMI25.pdf\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78fbb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#====================================\n",
    "# Random Forest model training\n",
    "#====================================\n",
    "\n",
    "model_RF = RandomForestClassifier(random_state=1)\n",
    "\n",
    "model_RF.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62953335",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print out the hyperparameters of the trained model\n",
    "model_RF.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d902e8f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# RF model prediction and metrics\n",
    "\n",
    "y_pred = model_RF.predict(X_test)\n",
    "\n",
    "print('RF model metrics:')\n",
    "print('Accuracy: {:.2f}'.format(accuracy_score(y_test, y_pred)))\n",
    "print('Precision: \\t {0:.2f}'.format(metrics.precision_score(y_test, y_pred)))\n",
    "print('Recall: \\t {0:.2f}'.format(metrics.recall_score(y_test, y_pred)))\n",
    "print('F1-score: \\t {0:.2f}'.format(metrics.f1_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f42090",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RF model performance with K-folds validation\n",
    "\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "model_RF_1 = RandomForestClassifier(random_state=1)\n",
    "scores1 = cross_val_score(model_RF_1, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "scores2 = cross_val_score(model_RF_1, X, y, scoring='precision', cv=cv, n_jobs=-1)\n",
    "scores3 = cross_val_score(model_RF_1, X, y, scoring='recall', cv=cv, n_jobs=-1)\n",
    "scores4 = cross_val_score(model_RF_1, X, y, scoring='f1', cv=cv, n_jobs=-1)\n",
    "scores5 = cross_val_score(model_RF_1, X, y, scoring='roc_auc', cv=cv, n_jobs=-1)\n",
    "print('Accuracy: %.2f' % (mean(scores1)))\n",
    "print('Precision: %.2f' % (mean(scores2)))\n",
    "print('Recall: %.2f' % (mean(scores3)))\n",
    "print('F1 Score: %.2f' % (mean(scores4)))\n",
    "print('AUC Score: %.2f' % (mean(scores5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abf7ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "importance = model_RF.feature_importances_\n",
    "# summarize feature importance\n",
    "for i,v in enumerate(importance):\n",
    "    print('Feature: %0d, Score: %.5f' % (i,v))\n",
    "# plot feature importance\n",
    "pyplot.bar([x for x in range(len(importance))], importance)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc11e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the weights of 10 most important variables affecting BMI≥25.0 in RF model \n",
    "\n",
    "weights = pd.Series(model_RF.feature_importances_, index = X.columns.values)\n",
    "print(weights.sort_values(ascending=True)[-10:].plot(kind='bar', color='grey'))\n",
    "plt.title('RF')\n",
    "plt.savefig(\"C:/Users/Toomas/Desktop/ITMI_Data/Tables and graphs/25_64/ML/RF_features_most_BMI25.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf13ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the least impact / RF model\n",
    "print(weights.sort_values(ascending=False)[-10:].plot(kind='barh', color='grey'))\n",
    "plt.title('RF')\n",
    "plt.savefig(\"C:/Users/Toomas/Desktop/ITMI_Data/Tables and graphs/25_64/ML/RF_features_least_BMI25.pdf\",bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f44d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# roc curve for RF model\n",
    "\n",
    "pred_prob2 = model_RF.predict_proba(X_test)\n",
    "fpr2, tpr2, thresh2 = roc_curve(y_test, pred_prob2[:,1], pos_label=1)\n",
    "\n",
    "# roc curve for tpr = fpr \n",
    "random_probs = [0 for i in range(len(y_test))]\n",
    "p_fpr, p_tpr, _ = roc_curve(y_test, random_probs, pos_label=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46bf1ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# computing auc score for RF\n",
    "auc_score2 = roc_auc_score(y_test, pred_prob2[:,1])\n",
    "print(auc_score2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b169497",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn')\n",
    "\n",
    "# plot roc curves\n",
    "plt.plot(tpr2, fpr2, linestyle='--',color='green', label='Random Forest')\n",
    "plt.plot(p_fpr, p_tpr, linestyle='--', color='blue')\n",
    "# title\n",
    "plt.title('ROC curve')\n",
    "# x label\n",
    "plt.xlabel('False Positive Rate')\n",
    "# y label\n",
    "plt.ylabel('True Positive Rate')\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.savefig(\"C:/Users/Toomas/Desktop/ITMI_Data/Tables and graphs/25_64/ML/ROC_curve_RF_BMI25.pdf\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e617a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#====================================\n",
    "# SVM model training\n",
    "#====================================\n",
    "\n",
    "model_SVM=SVC(probability = True, kernel ='linear', random_state=1) \n",
    "model_SVM.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37905e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print out the hyperparameters of the trained model\n",
    "model_SVM.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a5c404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM model prediction and metrics\n",
    "\n",
    "y_pred = model_SVM.predict(X_test)\n",
    "\n",
    "print('SVM model metrics:')\n",
    "print('Accuracy: {:.2f}'.format(accuracy_score(y_test, y_pred)))\n",
    "print('Precision: \\t {0:.2f}'.format(metrics.precision_score(y_test, y_pred)))\n",
    "print('Recall: \\t {0:.2f}'.format(metrics.recall_score(y_test, y_pred)))\n",
    "print('F1-score: \\t {0:.2f}'.format(metrics.f1_score(y_test, y_pred)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8fc24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM model performance with K-folds validation\n",
    "\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "model_SVM_1 = SVC(probability = True, kernel ='linear', random_state=1)\n",
    "scores1 = cross_val_score(model_SVM_1, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "scores2 = cross_val_score(model_SVM_1, X, y, scoring='precision', cv=cv, n_jobs=-1)\n",
    "scores3 = cross_val_score(model_SVM_1, X, y, scoring='recall', cv=cv, n_jobs=-1)\n",
    "scores4 = cross_val_score(model_SVM_1, X, y, scoring='f1', cv=cv, n_jobs=-1)\n",
    "scores5 = cross_val_score(model_SVM_1, X, y, scoring='roc_auc', cv=cv, n_jobs=-1)\n",
    "print('Accuracy: %.2f' % (mean(scores1)))\n",
    "print('Precision: %.2f' % (mean(scores2)))\n",
    "print('Recall: %.2f' % (mean(scores3)))\n",
    "print('F1 Score: %.2f' % (mean(scores4)))\n",
    "print('AUC Score: %.2f' % (mean(scores5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb4b106",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the weights of 10 most important variables affecting BMI≥25.0 in SVM model \n",
    "\n",
    "weights = pd.Series(model_SVM.coef_[0], index = X.columns.values)\n",
    "print(weights.sort_values(ascending=True)[-10:].plot(kind='bar', color='grey'))\n",
    "plt.title('SVM')\n",
    "plt.savefig(\"C:/Users/Toomas/Desktop/ITMI_Data/Tables and graphs/25_64/ML/SVM_features_most_BMI25.pdf\",bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f30354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the most negative impact / SVM model\n",
    "print(weights.sort_values(ascending=False)[-10:].plot(kind='barh', color='grey'))\n",
    "plt.title('SVM')\n",
    "plt.savefig(\"C:/Users/Toomas/Desktop/ITMI_Data/Tables and graphs/25_64/ML/SVM_features_least_BMI25.pdf\",bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f220e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# roc curve for SVM model\n",
    "\n",
    "pred_prob3 = model_SVM.predict_proba(X_test)\n",
    "fpr3, tpr3, thresh3 = roc_curve(y_test, pred_prob3[:,1], pos_label=1)\n",
    "\n",
    "# roc curve for tpr = fpr \n",
    "random_probs = [0 for i in range(len(y_test))]\n",
    "p_fpr, p_tpr, _ = roc_curve(y_test, random_probs, pos_label=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820ac97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# computing auc score for SVM\n",
    "auc_score3 = roc_auc_score(y_test, pred_prob3[:,1])\n",
    "print(auc_score3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f25d40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn')\n",
    "\n",
    "# plot roc curves\n",
    "plt.plot(tpr3, fpr3, linestyle='--',color='violet', label='SVM')\n",
    "plt.plot(p_fpr, p_tpr, linestyle='--', color='blue')\n",
    "# title\n",
    "plt.title('ROC curve')\n",
    "# x label\n",
    "plt.xlabel('False Positive Rate')\n",
    "# y label\n",
    "plt.ylabel('True Positive Rate')\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.savefig(\"C:/Users/Toomas/Desktop/ITMI_Data/Tables and graphs/25_64/ML/ROC_curve_SVM_BMI25.pdf\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7f5ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#====================================\n",
    "# Decision Tree model training\n",
    "#====================================\n",
    "\n",
    "model_DT = DecisionTreeClassifier(random_state=1)\n",
    "model_DT.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d14f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print out the hyperparameters of the trained model\n",
    "model_DT.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eabfcb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_DT.predict(X_test)\n",
    "\n",
    "print('DT model metrics:')\n",
    "print('Accuracy: {:.2f}'.format(accuracy_score(y_test, y_pred)))\n",
    "print('Precision: \\t {0:.2f}'.format(metrics.precision_score(y_test, y_pred)))\n",
    "print('Recall: \\t {0:.2f}'.format(metrics.recall_score(y_test, y_pred)))\n",
    "print('F1-score: \\t {0:.2f}'.format(metrics.f1_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af4d47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DT model performance with K-folds validation\n",
    "\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "model_DT_1 = DecisionTreeClassifier(random_state=1)\n",
    "scores1 = cross_val_score(model_DT_1, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "scores2 = cross_val_score(model_DT_1, X, y, scoring='precision', cv=cv, n_jobs=-1)\n",
    "scores3 = cross_val_score(model_DT_1, X, y, scoring='recall', cv=cv, n_jobs=-1)\n",
    "scores4 = cross_val_score(model_DT_1, X, y, scoring='f1', cv=cv, n_jobs=-1)\n",
    "scores5 = cross_val_score(model_DT_1, X, y, scoring='roc_auc', cv=cv, n_jobs=-1)\n",
    "print('Accuracy: %.2f' % (mean(scores1)))\n",
    "print('Precision: %.2f' % (mean(scores2)))\n",
    "print('Recall: %.2f' % (mean(scores3)))\n",
    "print('F1 Score: %.2f' % (mean(scores4)))\n",
    "print('AUC Score: %.2f' % (mean(scores5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a424c448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot feature important of DT model\n",
    "importance = model_DT.feature_importances_\n",
    "# summarize feature importance\n",
    "for i,v in enumerate(importance):\n",
    "    print('Feature: %0d, Score: %.5f' % (i,v))\n",
    "# plot feature importance\n",
    "pyplot.bar([x for x in range(len(importance))], importance)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe038a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the weights of 10 most important variables affecting BMI≥25.0 in DT model \n",
    "\n",
    "weights = pd.Series(model_DT.feature_importances_, index = X.columns.values)\n",
    "print(weights.sort_values(ascending=True)[-10:].plot(kind='bar', color='grey'))\n",
    "plt.title('DT')\n",
    "plt.savefig(\"C:/Users/Toomas/Desktop/ITMI_Data/Tables and graphs/25_64/ML/DT_features_most_BMI25.pdf\",bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b496d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the most negative impact / DT model\n",
    "print(weights.sort_values(ascending=False)[-10:].plot(kind='barh', color='grey'))\n",
    "plt.savefig(\"C:/Users/Toomas/Desktop/ITMI_Data/Tables and graphs/25_64/ML/DT_features_least_BMI25.pdf\",bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14aa2cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# roc curve for DT model\n",
    "\n",
    "pred_prob4 = model_DT.predict_proba(X_test)\n",
    "fpr4, tpr4, thresh4 = roc_curve(y_test, pred_prob4[:,1], pos_label=1)\n",
    "\n",
    "# roc curve for tpr = fpr \n",
    "random_probs = [0 for i in range(len(y_test))]\n",
    "p_fpr, p_tpr, _ = roc_curve(y_test, random_probs, pos_label=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ec1bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# computing auc score for DT\n",
    "auc_score4 = roc_auc_score(y_test, pred_prob4[:,1])\n",
    "print(auc_score4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc20ed86",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn')\n",
    "\n",
    "# plot roc curves\n",
    "plt.plot(tpr4, fpr4, linestyle='--',color='black', label='DT')\n",
    "plt.plot(p_fpr, p_tpr, linestyle='--', color='blue')\n",
    "# title\n",
    "plt.title('ROC curve')\n",
    "# x label\n",
    "plt.xlabel('False Positive Rate')\n",
    "# y label\n",
    "plt.ylabel('True Positive Rate')\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.savefig(\"C:/Users/Toomas/Desktop/ITMI_Data/Tables and graphs/25_64/ML/ROC_curve_DT_BMI25.pdf\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18717f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#====================================\n",
    "# Gaussian Naive Bayes model training\n",
    "#====================================\n",
    "\n",
    "model_NB = GaussianNB()\n",
    "model_NB.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca7edc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print out the hyperparameters of the trained model\n",
    "model_NB.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4542c46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_NB.predict(X_test)\n",
    "\n",
    "print('NB model metrics:')\n",
    "print('Accuracy: {:.2f}'.format(accuracy_score(y_test, y_pred)))\n",
    "print('Precision: \\t {0:.2f}'.format(metrics.precision_score(y_test, y_pred)))\n",
    "print('Recall: \\t {0:.2f}'.format(metrics.recall_score(y_test, y_pred)))\n",
    "print('F1-score: \\t {0:.2f}'.format(metrics.f1_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f598b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NB model performance with K-folds validation\n",
    "\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "model_NB_1 = GaussianNB()\n",
    "scores1 = cross_val_score(model_NB_1, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "scores2 = cross_val_score(model_NB_1, X, y, scoring='precision', cv=cv, n_jobs=-1)\n",
    "scores3 = cross_val_score(model_NB_1, X, y, scoring='recall', cv=cv, n_jobs=-1)\n",
    "scores4 = cross_val_score(model_NB_1, X, y, scoring='f1', cv=cv, n_jobs=-1)\n",
    "scores5 = cross_val_score(model_NB_1, X, y, scoring='roc_auc', cv=cv, n_jobs=-1)\n",
    "print('Accuracy: %.2f' % (mean(scores1)))\n",
    "print('Precision: %.2f' % (mean(scores2)))\n",
    "print('Recall: %.2f' % (mean(scores3)))\n",
    "print('F1 Score: %.2f' % (mean(scores4)))\n",
    "print('AUC Score: %.2f' % (mean(scores5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f7c132",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "imps = permutation_importance(model_NB, X_test, y_test)\n",
    "importances = imps.importances_mean\n",
    "std = imps.importances_std\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "for f in range(X_test.shape[1]):\n",
    "    print(\"%d. %s (%f)\" % (f + 1, features[indices[f]], importances[indices[f]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7faab423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# greatest impact / NB model\n",
    "\n",
    "weights = pd.Series(importances, index = X.columns.values)\n",
    "print(weights.sort_values(ascending=True)[-10:].plot(kind='bar', color='grey'))\n",
    "plt.title('NB')\n",
    "plt.savefig(\"C:/Users/Toomas/Desktop/ITMI_Data/Tables and graphs/25_64/ML/NB_features_most_BMI25.pdf\",bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc47e0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# smalles impact / NB model\n",
    "print(weights.sort_values(ascending=False)[-10:].plot(kind='barh', color='grey'))\n",
    "plt.savefig(\"C:/Users/Toomas/Desktop/ITMI_Data/Tables and graphs/25_64/ML/DT_features_most_BMI25.pdf\",bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c00f658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# roc curve for NB model\n",
    "\n",
    "pred_prob5 = model_NB.predict_proba(X_test)\n",
    "fpr5, tpr5, thresh5 = roc_curve(y_test, pred_prob5[:,1], pos_label=1)\n",
    "\n",
    "# roc curve for tpr = fpr \n",
    "random_probs = [0 for i in range(len(y_test))]\n",
    "p_fpr, p_tpr, _ = roc_curve(y_test, random_probs, pos_label=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c817e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# computing auc score for NB\n",
    "auc_score5 = roc_auc_score(y_test, pred_prob5[:,1])\n",
    "print(auc_score5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bee7d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn')\n",
    "\n",
    "# plot roc curves\n",
    "plt.plot(tpr5, fpr5, linestyle='--',color='red', label='NB')\n",
    "plt.plot(p_fpr, p_tpr, linestyle='--', color='blue')\n",
    "# title\n",
    "plt.title('ROC curve')\n",
    "# x label\n",
    "plt.xlabel('False Positive Rate')\n",
    "# y label\n",
    "plt.ylabel('True Positive Rate')\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.savefig(\"C:/Users/Toomas/Desktop/ITMI_Data/Tables and graphs/25_64/ML/ROC_curve_NB_BMI25.pdf\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1e9d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#====================================\n",
    "# KNN model training\n",
    "#====================================\n",
    "\n",
    "# testing accuracy for k from 1 to 40\n",
    "k_range = range(1,41)\n",
    "scores={}\n",
    "scores_list = []\n",
    "for k in k_range:\n",
    "    knn = KNeighborsClassifier(n_neighbors = k)\n",
    "    knn.fit(X_train,y_train)\n",
    "    y_pred = knn.predict(X_test)\n",
    "    scores[k] = metrics.accuracy_score(y_test,y_pred)\n",
    "    scores_list.append(metrics.accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc8e291",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting the relationship between k values and correspondgin testing accuracy\n",
    "\n",
    "plt.plot(k_range,scores_list, color='black')\n",
    "plt.xlabel('K value for KNN')\n",
    "plt.ylabel('Testing accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5502424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# k=31, as 31 is the odd number that provides best testing accuracy\n",
    "model_KNN = KNeighborsClassifier(n_neighbors=31)\n",
    "model_KNN.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b81673",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print out the hyperparameters of the trained model\n",
    "model_KNN.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ac0bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_KNN.predict(X_test)\n",
    "\n",
    "print('KNN model metrics:')\n",
    "print('Accuracy: {:.2f}'.format(accuracy_score(y_test, y_pred)))\n",
    "print('Precision: \\t {0:.2f}'.format(metrics.precision_score(y_test, y_pred)))\n",
    "print('Recall: \\t {0:.2f}'.format(metrics.recall_score(y_test, y_pred)))\n",
    "print('F1-score: \\t {0:.2f}'.format(metrics.f1_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8500588c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN model performance with K-folds validation\n",
    "\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "model_KNN_1 = KNeighborsClassifier()\n",
    "scores1 = cross_val_score(model_KNN_1, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "scores2 = cross_val_score(model_KNN_1, X, y, scoring='precision', cv=cv, n_jobs=-1)\n",
    "scores3 = cross_val_score(model_KNN_1, X, y, scoring='recall', cv=cv, n_jobs=-1)\n",
    "scores4 = cross_val_score(model_KNN_1, X, y, scoring='f1', cv=cv, n_jobs=-1)\n",
    "scores5 = cross_val_score(model_KNN_1, X, y, scoring='roc_auc', cv=cv, n_jobs=-1)\n",
    "print('Accuracy: %.2f' % (mean(scores1)))\n",
    "print('Precision: %.2f' % (mean(scores2)))\n",
    "print('Recall: %.2f' % (mean(scores3)))\n",
    "print('F1 Score: %.2f' % (mean(scores4)))\n",
    "print('AUC Score: %.2f' % (mean(scores5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8f3aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature importance is not defined for the KNN classification algorithm and there is no easy way to calucate it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb22c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# roc curve for KNN model\n",
    "\n",
    "pred_prob6 = model_KNN.predict_proba(X_test)\n",
    "fpr6, tpr6, thresh6 = roc_curve(y_test, pred_prob6[:,1], pos_label=1)\n",
    "\n",
    "# roc curve for tpr = fpr \n",
    "random_probs = [0 for i in range(len(y_test))]\n",
    "p_fpr, p_tpr, _ = roc_curve(y_test, random_probs, pos_label=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd9724f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# computing auc score for KNN\n",
    "auc_score6 = roc_auc_score(y_test, pred_prob6[:,1])\n",
    "print(auc_score6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49a9c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn')\n",
    "\n",
    "# plot roc curves\n",
    "plt.plot(tpr6, fpr6, linestyle='--',color='red', label='KNN')\n",
    "plt.plot(p_fpr, p_tpr, linestyle='--', color='blue')\n",
    "# title\n",
    "plt.title('ROC curve')\n",
    "# x label\n",
    "plt.xlabel('False Positive Rate')\n",
    "# y label\n",
    "plt.ylabel('True Positive Rate')\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.savefig(\"C:/Users/Toomas/Desktop/ITMI_Data/Tables and graphs/25_64/ML/ROC_curve_KNN_BMI25.pdf\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e752f98e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# a plot of roc curves of all 6 models\n",
    "plt.style.use('seaborn')\n",
    "\n",
    "# plot roc curves\n",
    "plt.plot(tpr1, fpr1, linestyle='--',color='orange', label='Logistic Regression')\n",
    "plt.plot(tpr2, fpr2, linestyle='--',color='green', label='Random Forest')\n",
    "plt.plot(tpr3, fpr3, linestyle='--',color='violet', label='Support Vector Machine')\n",
    "plt.plot(tpr4, fpr4, linestyle='--',color='blue', label='Decision Tree')\n",
    "plt.plot(tpr5, fpr5, linestyle='--',color='red', label='Naive Bayes')\n",
    "plt.plot(tpr6, fpr6, linestyle='--',color='brown', label='K-Nearest Neighbor')\n",
    "\n",
    "plt.plot(p_fpr, p_tpr, linestyle='--', color='black', linewidth=3)\n",
    "# title\n",
    "plt.title('ROC curve')\n",
    "# x label\n",
    "plt.xlabel('False Positive Rate')\n",
    "# y label\n",
    "plt.ylabel('True Positive Rate')\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.savefig(\"C:/Users/Toomas/Desktop/ITMI_Data/Tables and graphs/25_64/ML/ROC_curve_all6_BMI25.pdf\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c9b6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a plot of roc curves of all 6 models / black and white\n",
    "plt.style.use('seaborn')\n",
    "\n",
    "# plot roc curves\n",
    "plt.plot(tpr1, fpr1, linestyle=':',color = 'black',label='Logistic Regression')\n",
    "plt.plot(tpr2, fpr2, linestyle='-',color='black', label='Random Forest')\n",
    "plt.plot(tpr3, fpr3, linestyle='--',color='black', label='Support Vector Machine')\n",
    "plt.plot(tpr4, fpr4, linestyle='-.',color='black', label='Decisions Tree')\n",
    "plt.plot(tpr5, fpr5, linestyle='--',color='black', linewidth=3, label='Naive Bayes')\n",
    "plt.plot(tpr6, fpr6, linestyle='-.',color='black', label='K-Nearest Neighbor')\n",
    "\n",
    "plt.plot(p_fpr, p_tpr, linestyle='--', color='black', linewidth=3)\n",
    "# title\n",
    "plt.title('ROC curve')\n",
    "# x label\n",
    "plt.xlabel('False Positive Rate')\n",
    "# y label\n",
    "plt.ylabel('True Positive Rate')\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.savefig(\"C:/Users/Toomas/Desktop/ITMI_Data/Tables and graphs/25_64/ML/ROC_curve_all6_BW_BMI25.pdf\")\n",
    "plt.show();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
