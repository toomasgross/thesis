{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737d2272",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import seaborn as sns\n",
    "\n",
    "from matplotlib import pyplot\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6787df87",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2020 = pd.read_csv(\"C:/Users/Toomas/Desktop/ITMI_Data/Cleaned_datasets_25_64/Yearly/2020_cleaned_weights.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7022bb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop irrelevant columns from the analysis\n",
    "df_2020 = df_2020.drop(columns=['survey_year', 'respondent_id', 'age','bmi','bmi_four_groups','bmi_two_groups_split25', 'weights'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ec2242",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dummy variables\n",
    "# first change values from numeric to nominal for readable dummy labels\n",
    "\n",
    "df_2020['gender'] = df_2020['gender'].replace([1,2],['MALE','FEMALE'])\n",
    "df_2020['age_group'] = df_2020['age_group'].replace([1,2,3,4],['25_34','35_44','45_54','55_64'])\n",
    "df_2020['ethnicity_estonian_nonestonian'] = df_2020['ethnicity_estonian_nonestonian'].replace([1,2],['ESTONIAN','NON_ESTONIAN'])\n",
    "df_2020['education'] = df_2020['education'].replace([1,2,3,4],['PRIMARY_BASIC','SECONARY','SECONDARY_VOCATIONAL','HIGHER'])\n",
    "df_2020['income_per_household_member'] = df_2020['income_per_household_member'].replace([1,2,3,4],['QUARTILE_1','QUARTILE_2','QUARTILE_3','QUARTILE_4'])\n",
    "df_2020['chronic_disease'] = df_2020['chronic_disease'].replace([1,2],['YES','NO'])\n",
    "df_2020['smoking_history'] = df_2020['smoking_history'].replace([1,2,3,4],['NEVER','FORMERLY','SELDOM','DAILY'])\n",
    "df_2020['alcohol_standard_units_consumption_frequency'] = df_2020['alcohol_standard_units_consumption_frequency'].replace([1,2,3,4,5],['NEVER','<1x_MONTH','1+x_MONTH','1x_WEEK','ALMOST_DAILY'])\n",
    "df_2020['exercising_frequency'] = df_2020['exercising_frequency'].replace([1,2,3,4,5,6],['NEVER','1x_MONTH','2_3x_MONTH','1x_WEEK','2_3x_WEEK', '4_7X_WEEK'])\n",
    "df_2020['work_physical_effort_level'] = df_2020['work_physical_effort_level'].replace([1,2,3,4],['LITTLE','SOME','AVERAGE','A_LOT'])\n",
    "\n",
    "\n",
    "df_dummies = pd.get_dummies(df_2020, columns=['gender', 'age_group', \\\n",
    "                                              'ethnicity_estonian_nonestonian', 'education',\\\n",
    "                                              'income_per_household_member', 'chronic_disease',\\\n",
    "                                              'smoking_history',\\\n",
    "                                              'alcohol_standard_units_consumption_frequency',\\\n",
    "                                              'exercising_frequency',\\\n",
    "                                              'work_physical_effort_level'],drop_first=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c09e539",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print out names of columns\n",
    "\n",
    "df_dummies.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215298b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## correlation graph\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "plt.figure(figsize = (20,10))\n",
    "\n",
    "# get a color map\n",
    "\n",
    "my_cmap = cm.get_cmap('Accent')\n",
    "\n",
    "# Get correlation of bmi_two_groups_split30 with other variables\n",
    "\n",
    "df_dummies.corr()['bmi_two_groups_split30'].sort_values(ascending = False).plot(kind='bar', cmap=my_cmap)\n",
    "\n",
    " \n",
    "\n",
    "plt.title('Correlation of bmi_two_groups_split30 with other features', fontsize=20)\n",
    "plt.xlabel('Feature', fontsize=20)\n",
    "plt.ylabel('BMI<30.0 or BMIâ‰¥30.0', fontsize=20)\n",
    "plt.xticks(fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "plt.show()\n",
    "plt.savefig(\"C:/Users/Toomas/Desktop/ITMI_Data/Tables and graphs/25_64/ML/correlations.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2610f85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling all variables to the range of 0 to 1 before data learning process\n",
    "\n",
    "y = df_dummies['bmi_two_groups_split30'].values\n",
    "X = df_dummies.drop(columns = ['bmi_two_groups_split30'])\n",
    "\n",
    "features = X.columns.values\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "scaler.fit(X)\n",
    "X = pd.DataFrame(scaler.transform(X))\n",
    "X.columns = features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c094d816",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data into training and test set\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=1)\n",
    "\n",
    "print(\"The shape of X_train dataset: \", X_train.shape)\n",
    "print(\"The shape of y_train dataset: \", y_train.shape)\n",
    "print(\"The shape of X_test dataset: \", X_test.shape)\n",
    "print(\"The shape of y_test dataset: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9889d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# oversample the minority class\n",
    "\n",
    "sm = SMOTE(random_state=1)\n",
    "X_train_res,y_train_res = sm.fit_resample(X_train,y_train)\n",
    "\n",
    "print('After OverSampling, the shape of train_X: {}'.format(X_train_res.shape))\n",
    "print('After OverSampling, the shape of train_y: {} \\n'.format(y_train_res.shape))\n",
    "\n",
    "print(\"After OverSampling, counts of label '1': {}\".format(sum(y_train_res==1)))\n",
    "print(\"After OverSampling, counts of label '2': {}\".format(sum(y_train_res==2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed22453",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f326f979",
   "metadata": {},
   "outputs": [],
   "source": [
    "#===============================================================================\n",
    "# 01A Logistic regression model training / original data (without oversampling)\n",
    "#===============================================================================\n",
    "\n",
    "model_LR = LogisticRegression(random_state=1)\n",
    "model_LR.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6a3aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print out the hyperparameters of the trained model\n",
    "model_LR.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3f5650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LR model prediction and metrics (original dataset)\n",
    "y_pred = model_LR.predict(X_test)\n",
    "\n",
    "print('LR model metrics:')\n",
    "print('Accuracy: {:.2f}'.format(accuracy_score(y_test, y_pred)))\n",
    "print('Precision: \\t {0:.2f}'.format(metrics.precision_score(y_test, y_pred)))\n",
    "print('Recall: \\t {0:.2f}'.format(metrics.recall_score(y_test, y_pred)))\n",
    "print('F1-score: \\t {0:.2f}'.format(metrics.f1_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36eac7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LR model performance with K-folds validation (original dataset)\n",
    "\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "model_LR_1 = LogisticRegression(random_state=1)\n",
    "scores1 = cross_val_score(model_LR_1, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "scores2 = cross_val_score(model_LR_1, X, y, scoring='precision', cv=cv, n_jobs=-1)\n",
    "scores3 = cross_val_score(model_LR_1, X, y, scoring='recall', cv=cv, n_jobs=-1)\n",
    "scores4 = cross_val_score(model_LR_1, X, y, scoring='f1', cv=cv, n_jobs=-1)\n",
    "print('Accuracy: %.2f' % (mean(scores1)))\n",
    "print('Precision: %.2f' % (mean(scores2)))\n",
    "print('Recall: %.2f' % (mean(scores3)))\n",
    "print('F1 Score: %.2f' % (mean(scores4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76746b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get importance of features in LR model (original dataset)\n",
    "importance = model_LR.coef_[0]\n",
    "# summarize feature importance\n",
    "for i,v in enumerate(importance):\n",
    "    print('Feature: %0d, Score: %.5f' % (i,v))\n",
    "# plot feature importance\n",
    "pyplot.bar([x for x in range(len(importance))], importance)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19bab44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the weights of 10 most important features with association BMIâ‰¥30.0 in LR model (original dataset)\n",
    "\n",
    "weights = pd.Series(model_LR.coef_[0], index = X.columns.values)\n",
    "print(weights.sort_values(ascending=False)[:10].plot(kind='barh', color='grey'))\n",
    "#plt.tight_layout()\n",
    "plt.savefig(\"C:/Users/Toomas/Desktop/ITMI_Data/Tables and graphs/25_64/ML/LR_features_most_BMI30.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04a0deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the weights of 10 most important features with inverse association with BMIâ‰¥30.0 in LR model (original dataset)\n",
    "print(weights.sort_values(ascending=False)[-10:].plot(kind='barh', color='grey'))\n",
    "plt.savefig(\"C:/Users/Toomas/Desktop/ITMI_Data/Tables and graphs/25_64/ML/LR_features_least_BMI30.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1920e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# roc curve for LR model (original dataset)\n",
    "\n",
    "pred_prob1 = model_LR.predict_proba(X_test)\n",
    "fpr1, tpr1, thresh1 = roc_curve(y_test, pred_prob1[:,1], pos_label=1)\n",
    "\n",
    "# roc curve for tpr = fpr \n",
    "random_probs = [0 for i in range(len(y_test))]\n",
    "p_fpr, p_tpr, _ = roc_curve(y_test, random_probs, pos_label=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f214c5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# computing auc score for LR (original dataset)\n",
    "auc_score1 = roc_auc_score(y_test, pred_prob1[:,1])\n",
    "print(auc_score1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c0f568",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plot the roc curve for LR (original dataset)\n",
    "\n",
    "plt.style.use('seaborn')\n",
    "\n",
    "\n",
    "plt.plot(tpr1, fpr1, linestyle='--',color='orange', label='Logistic Regression')\n",
    "plt.plot(p_fpr, p_tpr, linestyle='--', color='blue')\n",
    "# title\n",
    "plt.title('ROC curve')\n",
    "# x label\n",
    "plt.xlabel('False Positive Rate')\n",
    "# y label\n",
    "plt.ylabel('True Positive Rate')\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.savefig(\"C:/Users/Toomas/Desktop/ITMI_Data/Tables and graphs/25_64/ML/ROC_curve_LR_BMI30.pdf\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c223e03b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e0f6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#============================================================\n",
    "# 01B Logistic regression model training / oversampled data\n",
    "#============================================================\n",
    "\n",
    "model_LR_res = LogisticRegression(random_state=1)\n",
    "model_LR_res.fit(X_train_res, y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f915e5e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Logistic regression model prediction and metrics (oversampled data)\n",
    "y_pred = model_LR_res.predict(X_test)\n",
    "\n",
    "print('LR model metrics:')\n",
    "print('Accuracy: {:.2f}'.format(accuracy_score(y_test, y_pred)))\n",
    "print('Precision: \\t {0:.2f}'.format(metrics.precision_score(y_test, y_pred)))\n",
    "print('Recall: \\t {0:.2f}'.format(metrics.recall_score(y_test, y_pred)))\n",
    "print('F1-score: \\t {0:.2f}'.format(metrics.f1_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a7b5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LR model performance with K-folds validation (oversampled data)\n",
    "\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "#oversamplling the whole dataset (not just training data)\n",
    "sm_all = SMOTE(random_state=1)\n",
    "X_res,y_res = sm_all.fit_resample(X,y)\n",
    "\n",
    "cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "model_LR_1_res = LogisticRegression(random_state=1)\n",
    "scores1 = cross_val_score(model_LR_1_res, X_res, y_res, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "scores2 = cross_val_score(model_LR_1_res, X_res, y_res, scoring='precision', cv=cv, n_jobs=-1)\n",
    "scores3 = cross_val_score(model_LR_1_res, X_res, y_res, scoring='recall', cv=cv, n_jobs=-1)\n",
    "scores4 = cross_val_score(model_LR_1_res, X_res, y_res, scoring='f1', cv=cv, n_jobs=-1)\n",
    "scores5 = cross_val_score(model_LR_1_res, X_res, y_res, scoring='roc_auc', cv=cv, n_jobs=-1)\n",
    "print('Accuracy: %.2f' % (mean(scores1)))\n",
    "print('Precision: %.2f' % (mean(scores2)))\n",
    "print('Recall: %.2f' % (mean(scores3)))\n",
    "print('F1 Score: %.2f' % (mean(scores4)))\n",
    "print('AUC Score: %.2f' % (mean(scores5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170b017f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get importance of features in LR model (oversampled dataset)\n",
    "importance = model_LR_res.coef_[0]\n",
    "# summarize feature importance\n",
    "for i,v in enumerate(importance):\n",
    "    print('Feature: %0d, Score: %.5f' % (i,v))\n",
    "# plot feature importance\n",
    "pyplot.bar([x for x in range(len(importance))], importance)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ffcd38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the weights of 10 most important features with association BMIâ‰¥30.0 in LR model (oversampled data)\n",
    "\n",
    "weights = pd.Series(model_LR_res.coef_[0], index = X.columns.values)\n",
    "print(weights.sort_values(ascending=True)[-10:].plot(kind='bar', color='grey'))\n",
    "plt.title('LR (+)')\n",
    "#plt.tight_layout()\n",
    "plt.savefig(\"C:/Users/Toomas/Desktop/ITMI_Data/Tables and graphs/25_64/ML/LR_features_most_BMI30_res.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88732f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the weights of 10 most important features with inverse association BMIâ‰¥30.0 in LR model (oversampled dataset)\n",
    "print(weights.sort_values(ascending=False)[-10:].plot(kind='bar', color='grey'))\n",
    "plt.title('LR (-)')\n",
    "plt.savefig(\"C:/Users/Toomas/Desktop/ITMI_Data/Tables and graphs/25_64/ML/LR_features_least_BMI30_res.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb4321d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# roc curve for LR model (oversampled data)\n",
    "\n",
    "pred_prob1 = model_LR_res.predict_proba(X_test)\n",
    "fpr1, tpr1, thresh1 = roc_curve(y_test, pred_prob1[:,1], pos_label=1)\n",
    "\n",
    "# roc curve for tpr = fpr \n",
    "random_probs = [0 for i in range(len(y_test))]\n",
    "p_fpr, p_tpr, _ = roc_curve(y_test, random_probs, pos_label=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d402d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# computing auc score for LR (oversampled data)\n",
    "auc_score1 = roc_auc_score(y_test, pred_prob1[:,1])\n",
    "print(auc_score1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded57cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the roc curve for LR (oversampled data)\n",
    "\n",
    "plt.style.use('seaborn')\n",
    "\n",
    "\n",
    "plt.plot(tpr1, fpr1, linestyle='--',color='orange', label='Logistic Regression')\n",
    "plt.plot(p_fpr, p_tpr, linestyle='--', color='blue')\n",
    "# title\n",
    "plt.title('ROC curve')\n",
    "# x label\n",
    "plt.xlabel('False Positive Rate')\n",
    "# y label\n",
    "plt.ylabel('True Positive Rate')\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.savefig(\"C:/Users/Toomas/Desktop/ITMI_Data/Tables and graphs/25_64/ML/ROC_curve_LR_BMI30_res.pdf\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073bc971",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78fbb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=========================================================================\n",
    "# 02A Random Forest model training / original data (without oversampling)\n",
    "#=========================================================================\n",
    "\n",
    "model_RF = RandomForestClassifier(random_state=1)\n",
    "\n",
    "model_RF.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397213c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print out the hyperparameters of the trained model (original data)\n",
    "model_RF.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d902e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RF model prediction and metrics (original data)\n",
    "\n",
    "y_pred = model_RF.predict(X_test)\n",
    "\n",
    "print('RF model metrics:')\n",
    "print('Accuracy: {:.2f}'.format(accuracy_score(y_test, y_pred)))\n",
    "print('Precision: \\t {0:.2f}'.format(metrics.precision_score(y_test, y_pred)))\n",
    "print('Recall: \\t {0:.2f}'.format(metrics.recall_score(y_test, y_pred)))\n",
    "print('F1-score: \\t {0:.2f}'.format(metrics.f1_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac20ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RF model performance with K-folds validation (original data)\n",
    "\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "model_RF_1 = RandomForestClassifier(random_state=1)\n",
    "scores1 = cross_val_score(model_RF_1, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "scores2 = cross_val_score(model_RF_1, X, y, scoring='precision', cv=cv, n_jobs=-1)\n",
    "scores3 = cross_val_score(model_RF_1, X, y, scoring='recall', cv=cv, n_jobs=-1)\n",
    "scores4 = cross_val_score(model_RF_1, X, y, scoring='f1', cv=cv, n_jobs=-1)\n",
    "print('Accuracy: %.2f' % (mean(scores1)))\n",
    "print('Precision: %.2f' % (mean(scores2)))\n",
    "print('Recall: %.2f' % (mean(scores3)))\n",
    "print('F1 Score: %.2f' % (mean(scores4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7b7299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculation of RF model feature importance (original data)\n",
    "\n",
    "importance = model_RF.feature_importances_\n",
    "# summarize feature importance\n",
    "for i,v in enumerate(importance):\n",
    "    print('Feature: %0d, Score: %.5f' % (i,v))\n",
    "# plot feature importance\n",
    "pyplot.bar([x for x in range(len(importance))], importance)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc11e8d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 10 most important features/ BMIâ‰¥30.0 in RF model (original data)\n",
    "\n",
    "weights = pd.Series(model_RF.feature_importances_, index = X.columns.values)\n",
    "print(weights.sort_values(ascending=False)[:10].plot(kind='barh', color='grey'))\n",
    "plt.savefig(\"C:/Users/Toomas/Desktop/ITMI_Data/Tables and graphs/25_64/ML/RF_features_most_BMI30.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf13ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10 least important features/ BMIâ‰¥30.0 in RF model (original data)\n",
    "print(weights.sort_values(ascending=False)[-10:].plot(kind='barh', color='grey'))\n",
    "plt.savefig(\"C:/Users/Toomas/Desktop/ITMI_Data/Tables and graphs/25_64/ML/RF_features_least_BMI30.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bdca3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# roc curve for RF model (original data)\n",
    "\n",
    "pred_prob2 = model_RF.predict_proba(X_test)\n",
    "fpr2, tpr2, thresh2 = roc_curve(y_test, pred_prob2[:,1], pos_label=1)\n",
    "\n",
    "# roc curve for tpr = fpr \n",
    "random_probs = [0 for i in range(len(y_test))]\n",
    "p_fpr, p_tpr, _ = roc_curve(y_test, random_probs, pos_label=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f63bc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# computing auc score for RF model (original data)\n",
    "auc_score2 = roc_auc_score(y_test, pred_prob2[:,1])\n",
    "print(auc_score2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec1080d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot roc curve for RF model (original data)\n",
    "\n",
    "plt.style.use('seaborn')\n",
    "\n",
    "\n",
    "plt.plot(tpr2, fpr2, linestyle='--',color='green', label='Random Forest')\n",
    "plt.plot(p_fpr, p_tpr, linestyle='--', color='blue')\n",
    "# title\n",
    "plt.title('ROC curve')\n",
    "# x label\n",
    "plt.xlabel('False Positive Rate')\n",
    "# y label\n",
    "plt.ylabel('True Positive Rate')\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.savefig(\"C:/Users/Toomas/Desktop/ITMI_Data/Tables and graphs/25_64/ML/ROC_curve_RF_BMI30.pdf\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabbeda0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596e01e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#===================================================\n",
    "# 02B Random Forest model training (oversampled data)\n",
    "#===================================================\n",
    "\n",
    "model_RF_res = RandomForestClassifier(random_state=1)\n",
    "model_RF_res.fit(X_train_res, y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303a7f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RF model prediction and metrics (oversampled data)\n",
    "\n",
    "y_pred = model_RF_res.predict(X_test)\n",
    "\n",
    "print('RF model metrics:')\n",
    "print('Accuracy: {:.2f}'.format(accuracy_score(y_test, y_pred)))\n",
    "print('Precision: \\t {0:.2f}'.format(metrics.precision_score(y_test, y_pred)))\n",
    "print('Recall: \\t {0:.2f}'.format(metrics.recall_score(y_test, y_pred)))\n",
    "print('F1-score: \\t {0:.2f}'.format(metrics.f1_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0223728d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RF model performance with K-folds validation (oversampled data)\n",
    "\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "#oversamplling the whole dataset (not just training data)\n",
    "sm_all = SMOTE(random_state=1)\n",
    "X_res,y_res = sm_all.fit_resample(X,y)\n",
    "\n",
    "cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "model_RF_1_res = RandomForestClassifier(random_state=1)\n",
    "scores1 = cross_val_score(model_RF_1_res, X_res, y_res, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "scores2 = cross_val_score(model_RF_1_res, X_res, y_res, scoring='precision', cv=cv, n_jobs=-1)\n",
    "scores3 = cross_val_score(model_RF_1_res, X_res, y_res, scoring='recall', cv=cv, n_jobs=-1)\n",
    "scores4 = cross_val_score(model_RF_1_res, X_res, y_res, scoring='f1', cv=cv, n_jobs=-1)\n",
    "scores5 = cross_val_score(model_RF_1_res, X_res, y_res, scoring='roc_auc', cv=cv, n_jobs=-1)\n",
    "print('Accuracy: %.2f' % (mean(scores1)))\n",
    "print('Precision: %.2f' % (mean(scores2)))\n",
    "print('Recall: %.2f' % (mean(scores3)))\n",
    "print('F1 Score: %.2f' % (mean(scores4)))\n",
    "print('AUC Score: %.2f' % (mean(scores5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79cb28eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# calculation of RF model feature importance (oversampled data)\n",
    "\n",
    "importance = model_RF_res.feature_importances_\n",
    "# summarize feature importance\n",
    "for i,v in enumerate(importance):\n",
    "    print('Feature: %0d, Score: %.5f' % (i,v))\n",
    "# plot feature importance\n",
    "pyplot.bar([x for x in range(len(importance))], importance)\n",
    "pyplot.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d819cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10 most important features/ BMIâ‰¥30.0 in RF model (oversampled data)\n",
    "\n",
    "weights = pd.Series(model_RF_res.feature_importances_, index = X.columns.values)\n",
    "print(weights.sort_values(ascending=True)[-10:].plot(kind='bar', color='grey'))\n",
    "plt.title('RF')\n",
    "plt.savefig(\"C:/Users/Toomas/Desktop/ITMI_Data/Tables and graphs/25_64/ML/RF_features_most_BMI30_res.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9338775",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10 least important features/ BMIâ‰¥30.0 in RF model (oversampled data)\n",
    "print(weights.sort_values(ascending=False)[-10:].plot(kind='barh', color='grey'))\n",
    "plt.title('RF')\n",
    "plt.savefig(\"C:/Users/Toomas/Desktop/ITMI_Data/Tables and graphs/25_64/ML/RF_features_least_BMI30_res.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f7a612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# roc curve for RF model (oversampled data)\n",
    "\n",
    "pred_prob2 = model_RF_res.predict_proba(X_test)\n",
    "fpr2, tpr2, thresh2 = roc_curve(y_test, pred_prob2[:,1], pos_label=1)\n",
    "\n",
    "# roc curve for tpr = fpr \n",
    "random_probs = [0 for i in range(len(y_test))]\n",
    "p_fpr, p_tpr, _ = roc_curve(y_test, random_probs, pos_label=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab0b698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# computing auc score for RF model (oversampled data)\n",
    "auc_score2 = roc_auc_score(y_test, pred_prob2[:,1])\n",
    "print(auc_score2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04664ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot roc curve for RF model (oversampled data)\n",
    "\n",
    "plt.style.use('seaborn')\n",
    "\n",
    "\n",
    "plt.plot(tpr2, fpr2, linestyle='--',color='green', label='Random Forest')\n",
    "plt.plot(p_fpr, p_tpr, linestyle='--', color='blue')\n",
    "# title\n",
    "plt.title('ROC curve')\n",
    "# x label\n",
    "plt.xlabel('False Positive Rate')\n",
    "# y label\n",
    "plt.ylabel('True Positive Rate')\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.savefig(\"C:/Users/Toomas/Desktop/ITMI_Data/Tables and graphs/25_64/ML/ROC_curve_RF_BMI30_res.pdf\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa401b33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e617a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#================================================================\n",
    "# 03A SVM model training /  original data (without oversampling)\n",
    "#================================================================\n",
    "\n",
    "model_SVM=SVC(probability = True, kernel ='linear', random_state=1)\n",
    "model_SVM.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407074c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print out the hyperparameters of the trained model (original data)\n",
    "model_SVM.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a5c404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM model prediction and metrics (original data)\n",
    "\n",
    "y_pred = model_SVM.predict(X_test)\n",
    "\n",
    "print('SVM model metrics:')\n",
    "print('Accuracy: {:.2f}'.format(accuracy_score(y_test, y_pred)))\n",
    "print('Precision: \\t {0:.2f}'.format(metrics.precision_score(y_test, y_pred)))\n",
    "print('Recall: \\t {0:.2f}'.format(metrics.recall_score(y_test, y_pred)))\n",
    "print('F1-score: \\t {0:.2f}'.format(metrics.f1_score(y_test, y_pred)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d665c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM model performance with K-folds validation (original data)\n",
    "\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "model_SVM_1 = SVC(probability = True, kernel ='linear',random_state=1)\n",
    "scores1 = cross_val_score(model_SVM_1, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "scores2 = cross_val_score(model_SVM_1, X, y, scoring='precision', cv=cv, n_jobs=-1)\n",
    "scores3 = cross_val_score(model_SVM_1, X, y, scoring='recall', cv=cv, n_jobs=-1)\n",
    "scores4 = cross_val_score(model_SVM_1, X, y, scoring='f1', cv=cv, n_jobs=-1)\n",
    "print('Accuracy: %.2f' % (mean(scores1)))\n",
    "print('Precision: %.2f' % (mean(scores2)))\n",
    "print('Recall: %.2f' % (mean(scores3)))\n",
    "print('F1 Score: %.2f' % (mean(scores4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb4b106",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10 most important variables affecting BMIâ‰¥30.0 in SVM model (original data) \n",
    "\n",
    "weights = pd.Series(model_SVM.coef_[0], index = X.columns.values)\n",
    "print(weights.sort_values(ascending=False)[:10].plot(kind='barh', color='grey'))\n",
    "plt.savefig(\"C:/Users/Toomas/Desktop/ITMI_Data/Tables and graphs/25_64/ML/SVM_features_most_BMI30.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f30354",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # 10 least important variables affecting BMIâ‰¥30.0 in SVM model (original data) \n",
    "print(weights.sort_values(ascending=False)[-10:].plot(kind='barh', color='grey'))\n",
    "plt.savefig(\"C:/Users/Toomas/Desktop/ITMI_Data/Tables and graphs/25_64/ML/SVM_features_least_BMI30.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93a6b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# roc curve for SVM model (original data) \n",
    "\n",
    "pred_prob3 = model_SVM.predict_proba(X_test)\n",
    "fpr3, tpr3, thresh3 = roc_curve(y_test, pred_prob3[:,1], pos_label=1)\n",
    "\n",
    "# roc curve for tpr = fpr \n",
    "random_probs = [0 for i in range(len(y_test))]\n",
    "p_fpr, p_tpr, _ = roc_curve(y_test, random_probs, pos_label=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7841d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# computing auc score for SVM (original data) \n",
    "auc_score3 = roc_auc_score(y_test, pred_prob3[:,1])\n",
    "print(auc_score3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49cc325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot roc curve for SVM model (original data)\n",
    "plt.style.use('seaborn')\n",
    "\n",
    "\n",
    "plt.plot(tpr3, fpr3, linestyle='--',color='violet', label='SVM')\n",
    "plt.plot(p_fpr, p_tpr, linestyle='--', color='blue')\n",
    "# title\n",
    "plt.title('ROC curve')\n",
    "# x label\n",
    "plt.xlabel('False Positive Rate')\n",
    "# y label\n",
    "plt.ylabel('True Positive Rate')\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.savefig(\"C:/Users/Toomas/Desktop/ITMI_Data/Tables and graphs/25_64/ML/ROC_curve_SVM_BMI30.pdf\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1d6e8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a793b7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#==========================================\n",
    "# 03B SVM model training (oversampled data)\n",
    "#==========================================\n",
    "\n",
    "model_SVM_res=SVC(probability = True, kernel ='linear', random_state=1)\n",
    "model_SVM_res.fit(X_train_res, y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f32e1c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# SVM model prediction and metrics (oversampled data)\n",
    "\n",
    "y_pred = model_SVM_res.predict(X_test)\n",
    "\n",
    "print('SVM model metrics:')\n",
    "print('Accuracy: {:.2f}'.format(accuracy_score(y_test, y_pred)))\n",
    "print('Precision: \\t {0:.2f}'.format(metrics.precision_score(y_test, y_pred)))\n",
    "print('Recall: \\t {0:.2f}'.format(metrics.recall_score(y_test, y_pred)))\n",
    "print('F1-score: \\t {0:.2f}'.format(metrics.f1_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41286f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM model performance with K-folds validation (oversampled data)\n",
    "\n",
    "\n",
    "#oversamplling the whole dataset (not just training data)\n",
    "sm_all = SMOTE(random_state=1)\n",
    "X_res,y_res = sm_all.fit_resample(X,y)\n",
    "\n",
    "cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "model_SVM_1_res = SVC(probability = True, kernel ='linear', random_state=1)\n",
    "scores1 = cross_val_score(model_SVM_1_res, X_res, y_res, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "scores2 = cross_val_score(model_SVM_1_res, X_res, y_res, scoring='precision', cv=cv, n_jobs=-1)\n",
    "scores3 = cross_val_score(model_SVM_1_res, X_res, y_res, scoring='recall', cv=cv, n_jobs=-1)\n",
    "scores4 = cross_val_score(model_SVM_1_res, X_res, y_res, scoring='f1', cv=cv, n_jobs=-1)\n",
    "scores5 = cross_val_score(model_SVM_1_res, X_res, y_res, scoring='roc_auc', cv=cv, n_jobs=-1)\n",
    "print('Accuracy: %.2f' % (mean(scores1)))\n",
    "print('Precision: %.2f' % (mean(scores2)))\n",
    "print('Recall: %.2f' % (mean(scores3)))\n",
    "print('F1 Score: %.2f' % (mean(scores4)))\n",
    "print('AUC Score: %.2f' % (mean(scores5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0f6c2f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 10 most important variables affecting BMIâ‰¥30.0 in SVM model (oversampled data) \n",
    "\n",
    "weights = pd.Series(model_SVM_res.coef_[0], index = X.columns.values)\n",
    "print(weights.sort_values(ascending=True)[-10:].plot(kind='bar', color='grey'))\n",
    "plt.title('SVM')\n",
    "plt.savefig(\"C:/Users/Toomas/Desktop/ITMI_Data/Tables and graphs/25_64/ML/SVM_features_most_BMI30_res.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dacaa37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 10 least important variables affecting BMIâ‰¥30.0 in SVM model (oversampled data) \n",
    "print(weights.sort_values(ascending=False)[-10:].plot(kind='barh', color='grey'))\n",
    "plt.title('SVM')\n",
    "plt.savefig(\"C:/Users/Toomas/Desktop/ITMI_Data/Tables and graphs/25_64/ML/SVM_features_least_BMI30_res.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1106bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# roc curve for SVM model (oversampled data) \n",
    "\n",
    "pred_prob3 = model_SVM_res.predict_proba(X_test)\n",
    "fpr3, tpr3, thresh3 = roc_curve(y_test, pred_prob3[:,1], pos_label=1)\n",
    "\n",
    "# roc curve for tpr = fpr \n",
    "random_probs = [0 for i in range(len(y_test))]\n",
    "p_fpr, p_tpr, _ = roc_curve(y_test, random_probs, pos_label=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64257da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# computing auc score for SVM (oversampled data) \n",
    "auc_score3 = roc_auc_score(y_test, pred_prob3[:,1])\n",
    "print(auc_score3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992af7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot roc curve for SVM model (oversampled data)\n",
    "plt.style.use('seaborn')\n",
    "\n",
    "\n",
    "plt.plot(tpr3, fpr3, linestyle='--',color='violet', label='SVM')\n",
    "plt.plot(p_fpr, p_tpr, linestyle='--', color='blue')\n",
    "# title\n",
    "plt.title('ROC curve')\n",
    "# x label\n",
    "plt.xlabel('False Positive Rate')\n",
    "# y label\n",
    "plt.ylabel('True Positive Rate')\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.savefig(\"C:/Users/Toomas/Desktop/ITMI_Data/Tables and graphs/25_64/ML/ROC_curve_SVM_BMI30_res.pdf\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bdf75dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7f5ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=======================================================================\n",
    "# 4A Decision Tree model training / original data (without oversampling)\n",
    "#=======================================================================\n",
    "\n",
    "model_DT = DecisionTreeClassifier(random_state=1)\n",
    "model_DT.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2310d4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print out the hyperparameters of the trained model (original data)\n",
    "model_DT.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eabfcb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DT model prediction and metrics (original data)\n",
    "\n",
    "y_pred = model_DT.predict(X_test)\n",
    "\n",
    "print('DT model metrics:')\n",
    "print('Accuracy: {:.2f}'.format(accuracy_score(y_test, y_pred)))\n",
    "print('Precision: \\t {0:.2f}'.format(metrics.precision_score(y_test, y_pred)))\n",
    "print('Recall: \\t {0:.2f}'.format(metrics.recall_score(y_test, y_pred)))\n",
    "print('F1-score: \\t {0:.2f}'.format(metrics.f1_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043a6115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DT model performance with K-folds validation (original data)\n",
    "\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "model_DT_1 = DecisionTreeClassifier(random_state=1)\n",
    "scores1 = cross_val_score(model_DT_1, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "scores2 = cross_val_score(model_DT_1, X, y, scoring='precision', cv=cv, n_jobs=-1)\n",
    "scores3 = cross_val_score(model_DT_1, X, y, scoring='recall', cv=cv, n_jobs=-1)\n",
    "scores4 = cross_val_score(model_DT_1, X, y, scoring='f1', cv=cv, n_jobs=-1)\n",
    "print('Accuracy: %.2f' % (mean(scores1)))\n",
    "print('Precision: %.2f' % (mean(scores2)))\n",
    "print('Recall: %.2f' % (mean(scores3)))\n",
    "print('F1 Score: %.2f' % (mean(scores4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67704a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot feature important of DT model (original data)\n",
    "importance = model_DT.feature_importances_\n",
    "# summarize feature importance\n",
    "for i,v in enumerate(importance):\n",
    "    print('Feature: %0d, Score: %.5f' % (i,v))\n",
    "# plot feature importance\n",
    "pyplot.bar([x for x in range(len(importance))], importance)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe038a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10 most important variables affecting BMIâ‰¥25.0 in DT model  (original data)\n",
    "\n",
    "weights = pd.Series(model_DT.feature_importances_, index = X.columns.values)\n",
    "print(weights.sort_values(ascending=False)[:10].plot(kind='barh', color='grey'))\n",
    "plt.savefig(\"C:/Users/Toomas/Desktop/ITMI_Data/Tables and graphs/25_64/ML/DT_features_most_BMI30.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b496d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10 least important variables affecting BMIâ‰¥25.0 in DT model  (original data)\n",
    "print(weights.sort_values(ascending=False)[-10:].plot(kind='barh', color='grey'))\n",
    "plt.savefig(\"C:/Users/Toomas/Desktop/ITMI_Data/Tables and graphs/25_64/ML/DT_features_least_BMI30.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc289cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# roc curve for DT model (original data)\n",
    "\n",
    "pred_prob4 = model_DT.predict_proba(X_test)\n",
    "fpr4, tpr4, thresh4 = roc_curve(y_test, pred_prob4[:,1], pos_label=1)\n",
    "\n",
    "# roc curve for tpr = fpr \n",
    "random_probs = [0 for i in range(len(y_test))]\n",
    "p_fpr, p_tpr, _ = roc_curve(y_test, random_probs, pos_label=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9df7b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# computing auc score for DT (original data)\n",
    "auc_score4 = roc_auc_score(y_test, pred_prob4[:,1])\n",
    "print(auc_score4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1fe94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot roc curve for DT (original data)\n",
    "\n",
    "plt.style.use('seaborn')\n",
    "\n",
    "\n",
    "plt.plot(tpr4, fpr4, linestyle='--',color='black', label='DT')\n",
    "plt.plot(p_fpr, p_tpr, linestyle='--', color='blue')\n",
    "# title\n",
    "plt.title('ROC curve')\n",
    "# x label\n",
    "plt.xlabel('False Positive Rate')\n",
    "# y label\n",
    "plt.ylabel('True Positive Rate')\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.savefig(\"C:/Users/Toomas/Desktop/ITMI_Data/Tables and graphs/25_64/ML/ROC_curve_DT_BMI30.pdf\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1f8da2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5801b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#===================================================\n",
    "# 4B Decision Tree model training (oversampled data)\n",
    "#===================================================\n",
    "\n",
    "model_DT_res = DecisionTreeClassifier(random_state=1)\n",
    "model_DT_res.fit(X_train_res, y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed1c522",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# DT model prediction and metrics (oversampled data)\n",
    "\n",
    "y_pred = model_DT_res.predict(X_test)\n",
    "\n",
    "print('DT model metrics:')\n",
    "print('Accuracy: {:.2f}'.format(accuracy_score(y_test, y_pred)))\n",
    "print('Precision: \\t {0:.2f}'.format(metrics.precision_score(y_test, y_pred)))\n",
    "print('Recall: \\t {0:.2f}'.format(metrics.recall_score(y_test, y_pred)))\n",
    "print('F1-score: \\t {0:.2f}'.format(metrics.f1_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ad5910",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DT model performance with K-folds validation (oversampled data)\n",
    "\n",
    "\n",
    "#oversamplling the whole dataset (not just training data)\n",
    "sm_all = SMOTE(random_state=1)\n",
    "X_res,y_res = sm_all.fit_resample(X,y)\n",
    "\n",
    "cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "model_DT_1_res = DecisionTreeClassifier(random_state=1)\n",
    "scores1 = cross_val_score(model_DT_1_res, X_res, y_res, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "scores2 = cross_val_score(model_DT_1_res, X_res, y_res, scoring='precision', cv=cv, n_jobs=-1)\n",
    "scores3 = cross_val_score(model_DT_1_res, X_res, y_res, scoring='recall', cv=cv, n_jobs=-1)\n",
    "scores4 = cross_val_score(model_DT_1_res, X_res, y_res, scoring='f1', cv=cv, n_jobs=-1)\n",
    "scores5 = cross_val_score(model_DT_1_res, X_res, y_res, scoring='roc_auc', cv=cv, n_jobs=-1)\n",
    "print('Accuracy: %.2f' % (mean(scores1)))\n",
    "print('Precision: %.2f' % (mean(scores2)))\n",
    "print('Recall: %.2f' % (mean(scores3)))\n",
    "print('F1 Score: %.2f' % (mean(scores4)))\n",
    "print('AUC Score: %.2f' % (mean(scores5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbb292d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10 most important variables affecting BMIâ‰¥25.0 in DT model  (oversampled data)\n",
    "\n",
    "weights = pd.Series(model_DT_res.feature_importances_, index = X.columns.values)\n",
    "print(weights.sort_values(ascending=True)[-10:].plot(kind='bar', color='grey'))\n",
    "plt.title('DT')\n",
    "plt.savefig(\"C:/Users/Toomas/Desktop/ITMI_Data/Tables and graphs/25_64/ML/DT_features_most_BMI30_RES.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7167b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10 least important variables affecting BMIâ‰¥25.0 in DT model  (oversampled data)\n",
    "print(weights.sort_values(ascending=False)[-10:].plot(kind='barh', color='grey'))\n",
    "plt.savefig(\"C:/Users/Toomas/Desktop/ITMI_Data/Tables and graphs/25_64/ML/DT_features_least_BMI30.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05df5566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# roc curve for DT model (oversampled data)\n",
    "\n",
    "pred_prob4 = model_DT_res.predict_proba(X_test)\n",
    "fpr4, tpr4, thresh4 = roc_curve(y_test, pred_prob4[:,1], pos_label=1)\n",
    "\n",
    "# roc curve for tpr = fpr \n",
    "random_probs = [0 for i in range(len(y_test))]\n",
    "p_fpr, p_tpr, _ = roc_curve(y_test, random_probs, pos_label=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee4e40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_score4 = roc_auc_score(y_test, pred_prob4[:,1])\n",
    "print(auc_score4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b3a036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot roc curve for DT (oversampled data)\n",
    "\n",
    "plt.style.use('seaborn')\n",
    "\n",
    "\n",
    "plt.plot(tpr4, fpr4, linestyle='--',color='black', label='DT')\n",
    "plt.plot(p_fpr, p_tpr, linestyle='--', color='blue')\n",
    "# title\n",
    "plt.title('ROC curve')\n",
    "# x label\n",
    "plt.xlabel('False Positive Rate')\n",
    "# y label\n",
    "plt.ylabel('True Positive Rate')\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.savefig(\"C:/Users/Toomas/Desktop/ITMI_Data/Tables and graphs/25_64/ML/ROC_curve_DT_BMI30_res.pdf\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be46ca56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18717f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================================================\n",
    "# 5A (Gaussian) Naive Bayes model training / original data (without oversampling)\n",
    "#=================================================================================\n",
    "\n",
    "model_NB = GaussianNB()\n",
    "model_NB.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bfe37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print out the hyperparameters of the trained model (original data)\n",
    "model_NB.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4542c46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NB model prediction and metrics (original data)\n",
    "\n",
    "y_pred = model_NB.predict(X_test)\n",
    "\n",
    "print('NB model metrics:')\n",
    "print('Accuracy: {:.2f}'.format(accuracy_score(y_test, y_pred)))\n",
    "print('Precision: \\t {0:.2f}'.format(metrics.precision_score(y_test, y_pred)))\n",
    "print('Recall: \\t {0:.2f}'.format(metrics.recall_score(y_test, y_pred)))\n",
    "print('F1-score: \\t {0:.2f}'.format(metrics.f1_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01733a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NB model performance with K-folds validation (original data)\n",
    "\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "model_NB_1 = GaussianNB()\n",
    "scores1 = cross_val_score(model_NB_1, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "scores2 = cross_val_score(model_NB_1, X, y, scoring='precision', cv=cv, n_jobs=-1)\n",
    "scores3 = cross_val_score(model_NB_1, X, y, scoring='recall', cv=cv, n_jobs=-1)\n",
    "scores4 = cross_val_score(model_NB_1, X, y, scoring='f1', cv=cv, n_jobs=-1)\n",
    "print('Accuracy: %.2f' % (mean(scores1)))\n",
    "print('Precision: %.2f' % (mean(scores2)))\n",
    "print('Recall: %.2f' % (mean(scores3)))\n",
    "print('F1 Score: %.2f' % (mean(scores4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4124d0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot feature important of NB model (original data)\n",
    "\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "imps = permutation_importance(model_NB, X_test, y_test)\n",
    "importances = imps.importances_mean\n",
    "std = imps.importances_std\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "for f in range(X_test.shape[1]):\n",
    "    print(\"%d. %s (%f)\" % (f + 1, features[indices[f]], importances[indices[f]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9184e842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# greatest impact / NB model  (original data)\n",
    "\n",
    "weights = pd.Series(importances, index = X.columns.values)\n",
    "print(weights.sort_values(ascending=False)[:10].plot(kind='barh', color='grey'))\n",
    "plt.savefig(\"C:/Users/Toomas/Desktop/ITMI_Data/Tables and graphs/25_64/ML/NB_features_most_BMI30.pdf\", bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f492fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# least impact / NB model  (original data)\n",
    "print(weights.sort_values(ascending=False)[-10:].plot(kind='barh', color='grey'))\n",
    "plt.savefig(\"C:/Users/Toomas/Desktop/ITMI_Data/Tables and graphs/25_64/ML/NB_features_least_BMI30.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4649e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# roc curve for NB model  (original data)\n",
    "\n",
    "pred_prob5 = model_NB.predict_proba(X_test)\n",
    "fpr5, tpr5, thresh5 = roc_curve(y_test, pred_prob5[:,1], pos_label=1)\n",
    "\n",
    "# roc curve for tpr = fpr \n",
    "random_probs = [0 for i in range(len(y_test))]\n",
    "p_fpr, p_tpr, _ = roc_curve(y_test, random_probs, pos_label=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7fe797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# computing auc score for NB  (original data)\n",
    "auc_score5 = roc_auc_score(y_test, pred_prob5[:,1])\n",
    "print(auc_score5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016e275b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot roc curves for NB  (original data)\n",
    "\n",
    "plt.style.use('seaborn')\n",
    "\n",
    "plt.plot(tpr5, fpr5, linestyle='--',color='red', label='NB')\n",
    "plt.plot(p_fpr, p_tpr, linestyle='--', color='blue')\n",
    "# title\n",
    "plt.title('ROC curve')\n",
    "# x label\n",
    "plt.xlabel('False Positive Rate')\n",
    "# y label\n",
    "plt.ylabel('True Positive Rate')\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.savefig(\"C:/Users/Toomas/Desktop/ITMI_Data/Tables and graphs/25_64/ML/ROC_curve_NB_BMI30.pdf\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0cadb86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5f7cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#============================================================\n",
    "# 5B (Gaussian) Naive Bayes model training (oversampled data)\n",
    "#============================================================\n",
    "\n",
    "model_NB_res = GaussianNB()\n",
    "model_NB_res.fit(X_train_res, y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00077c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NB model prediction and metrics (oversampled data)\n",
    "\n",
    "y_pred = model_NB_res.predict(X_test)\n",
    "\n",
    "print('NB model metrics:')\n",
    "print('Accuracy: {:.2f}'.format(accuracy_score(y_test, y_pred)))\n",
    "print('Precision: \\t {0:.2f}'.format(metrics.precision_score(y_test, y_pred)))\n",
    "print('Recall: \\t {0:.2f}'.format(metrics.recall_score(y_test, y_pred)))\n",
    "print('F1-score: \\t {0:.2f}'.format(metrics.f1_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526f99a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NB model performance with K-folds validation (oversampled data)\n",
    "\n",
    "\n",
    "#oversamplling the whole dataset (not just training data)\n",
    "sm_all = SMOTE(random_state=1)\n",
    "X_res,y_res = sm_all.fit_resample(X,y)\n",
    "\n",
    "cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "model_NB_1_res = GaussianNB()\n",
    "scores1 = cross_val_score(model_NB_1_res, X_res, y_res, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "scores2 = cross_val_score(model_NB_1_res, X_res, y_res, scoring='precision', cv=cv, n_jobs=-1)\n",
    "scores3 = cross_val_score(model_NB_1_res, X_res, y_res, scoring='recall', cv=cv, n_jobs=-1)\n",
    "scores4 = cross_val_score(model_NB_1_res, X_res, y_res, scoring='f1', cv=cv, n_jobs=-1)\n",
    "scores5 = cross_val_score(model_NB_1_res, X_res, y_res, scoring='roc_auc', cv=cv, n_jobs=-1)\n",
    "print('Accuracy: %.2f' % (mean(scores1)))\n",
    "print('Precision: %.2f' % (mean(scores2)))\n",
    "print('Recall: %.2f' % (mean(scores3)))\n",
    "print('F1 Score: %.2f' % (mean(scores4)))\n",
    "print('AUC Score: %.2f' % (mean(scores5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be0ab83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# greatest impact / NB model  (oversampled  data)\n",
    "\n",
    "weights = pd.Series(importances, index = X.columns.values)\n",
    "print(weights.sort_values(ascending=True)[-10:].plot(kind='bar', color='grey'))\n",
    "plt.title('NB')\n",
    "plt.savefig(\"C:/Users/Toomas/Desktop/ITMI_Data/Tables and graphs/25_64/ML/NB_features_most_BMI30_RES.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992fd16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# least impact / NB model  (oversampled data)\n",
    "print(weights.sort_values(ascending=False)[-10:].plot(kind='barh', color='grey'))\n",
    "plt.title('NB')\n",
    "plt.savefig(\"C:/Users/Toomas/Desktop/ITMI_Data/Tables and graphs/25_64/ML/NB_features_least_BMI30_res.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6fc8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# roc curve for NB model  (oversampled data)\n",
    "\n",
    "pred_prob5 = model_NB_res.predict_proba(X_test)\n",
    "fpr5, tpr5, thresh5 = roc_curve(y_test, pred_prob5[:,1], pos_label=1)\n",
    "\n",
    "# roc curve for tpr = fpr \n",
    "random_probs = [0 for i in range(len(y_test))]\n",
    "p_fpr, p_tpr, _ = roc_curve(y_test, random_probs, pos_label=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac59ca59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# computing auc score for NB  (oversampled data)\n",
    "auc_score5 = roc_auc_score(y_test, pred_prob5[:,1])\n",
    "print(auc_score5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a7a259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot roc curves for NB  (oversampled data)\n",
    "\n",
    "plt.style.use('seaborn')\n",
    "\n",
    "plt.plot(tpr5, fpr5, linestyle='--',color='red', label='NB')\n",
    "plt.plot(p_fpr, p_tpr, linestyle='--', color='blue')\n",
    "# title\n",
    "plt.title('ROC curve')\n",
    "# x label\n",
    "plt.xlabel('False Positive Rate')\n",
    "# y label\n",
    "plt.ylabel('True Positive Rate')\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.savefig(\"C:/Users/Toomas/Desktop/ITMI_Data/Tables and graphs/25_64/ML/ROC_curve_NB_BMI30_res.pdf\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfebc00c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2965ee3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#==============================================================\n",
    "# 6A KNN model training / original data (without oversampling)\n",
    "#==============================================================\n",
    "\n",
    "# testing accuracy for k from 1 to 40\n",
    "k_range = range(1,41)\n",
    "scores={}\n",
    "scores_list = []\n",
    "for k in k_range:\n",
    "    knn = KNeighborsClassifier(n_neighbors = k)\n",
    "    knn.fit(X_train,y_train)\n",
    "    y_pred = knn.predict(X_test)\n",
    "    scores[k] = metrics.accuracy_score(y_test,y_pred)\n",
    "    scores_list.append(metrics.accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f913a42d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#plotting the relationship between k values and correspondgin testing accuracy (original data)\n",
    "\n",
    "plt.plot(k_range,scores_list, color='black')\n",
    "plt.xlabel('K value for KNN')\n",
    "plt.ylabel('Testing accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3772537a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the final model should have k=13 (original data) - I am choosing an odd k-value to avoid a situation\n",
    "model_KNN = KNeighborsClassifier(n_neighbors=13)\n",
    "model_KNN.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae3f9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print out the hyperparameters of the trained model (original data)\n",
    "model_KNN.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966732d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN model prediction and metrics (original data)\n",
    "\n",
    "y_pred = model_KNN.predict(X_test)\n",
    "\n",
    "print('KNN model metrics:')\n",
    "print('Accuracy: {:.2f}'.format(accuracy_score(y_test, y_pred)))\n",
    "print('Precision: \\t {0:.2f}'.format(metrics.precision_score(y_test, y_pred)))\n",
    "print('Recall: \\t {0:.2f}'.format(metrics.recall_score(y_test, y_pred)))\n",
    "print('F1-score: \\t {0:.2f}'.format(metrics.f1_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d557e303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN model performance with K-folds validation (original data)\n",
    "\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "model_KNN_1 = KNeighborsClassifier()\n",
    "scores1 = cross_val_score(model_KNN_1, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "scores2 = cross_val_score(model_KNN_1, X, y, scoring='precision', cv=cv, n_jobs=-1)\n",
    "scores3 = cross_val_score(model_KNN_1, X, y, scoring='recall', cv=cv, n_jobs=-1)\n",
    "scores4 = cross_val_score(model_KNN_1, X, y, scoring='f1', cv=cv, n_jobs=-1)\n",
    "print('Accuracy: %.2f' % (mean(scores1)))\n",
    "print('Precision: %.2f' % (mean(scores2)))\n",
    "print('Recall: %.2f' % (mean(scores3)))\n",
    "print('F1 Score: %.2f' % (mean(scores4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333f6b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature importance is not defined for the KNN classification algorithm and there is no easy way to calucate it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77816501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# roc curve for KNN model (original data)\n",
    "\n",
    "pred_prob6 = model_KNN.predict_proba(X_test)\n",
    "fpr6, tpr6, thresh6 = roc_curve(y_test, pred_prob6[:,1], pos_label=1)\n",
    "\n",
    "# roc curve for tpr = fpr \n",
    "random_probs = [0 for i in range(len(y_test))]\n",
    "p_fpr, p_tpr, _ = roc_curve(y_test, random_probs, pos_label=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6afc1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# computing auc score for KNN (original data)\n",
    "auc_score6 = roc_auc_score(y_test, pred_prob6[:,1])\n",
    "print(auc_score6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a703fc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot roc curve (original data)\n",
    "\n",
    "plt.style.use('seaborn')\n",
    "\n",
    "\n",
    "plt.plot(tpr6, fpr6, linestyle='--',color='red', label='KNN')\n",
    "plt.plot(p_fpr, p_tpr, linestyle='--', color='blue')\n",
    "# title\n",
    "plt.title('ROC curve')\n",
    "# x label\n",
    "plt.xlabel('False Positive Rate')\n",
    "# y label\n",
    "plt.ylabel('True Positive Rate')\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.savefig(\"C:/Users/Toomas/Desktop/ITMI_Data/Tables and graphs/25_64/ML/ROC_curve_KNN_BMI30.pdf\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bcf6814",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8a39ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#===========================================\n",
    "# 6B KNN model training (oversampled data)\n",
    "#===========================================\n",
    "\n",
    "# testing accuracy for k from 1 to 40\n",
    "k_range = range(1,41)\n",
    "scores={}\n",
    "scores_list = []\n",
    "for k in k_range:\n",
    "    knn = KNeighborsClassifier(n_neighbors = k)\n",
    "    knn.fit(X_train_res,y_train_res)\n",
    "    y_pred = knn.predict(X_test)\n",
    "    scores[k] = metrics.accuracy_score(y_test,y_pred)\n",
    "    scores_list.append(metrics.accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0886a048",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting the relationship between k values and correspondgin testing accuracy (oversampled data)\n",
    "\n",
    "plt.plot(k_range,scores_list, color='black')\n",
    "plt.xlabel('K value for KNN')\n",
    "plt.ylabel('Testing accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a80471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the final model should have k=3, as the odd number (to avoid tie) beyond 1 with highes testing accuracy (oversampled data)\n",
    "model_KNN_res = KNeighborsClassifier(n_neighbors=3)\n",
    "model_KNN_res.fit(X_train_res, y_train_res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6d9709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN model prediction and metrics (oversampled data)\n",
    "\n",
    "y_pred = model_KNN_res.predict(X_test)\n",
    "\n",
    "print('KNN model metrics:')\n",
    "print('Accuracy: {:.2f}'.format(accuracy_score(y_test, y_pred)))\n",
    "print('Precision: \\t {0:.2f}'.format(metrics.precision_score(y_test, y_pred)))\n",
    "print('Recall: \\t {0:.2f}'.format(metrics.recall_score(y_test, y_pred)))\n",
    "print('F1-score: \\t {0:.2f}'.format(metrics.f1_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a90ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN model performance with K-folds validation (oversampled data)\n",
    "\n",
    "\n",
    "#oversampling the whole dataset (not just training data)\n",
    "sm_all = SMOTE(random_state=1)\n",
    "X_res,y_res = sm_all.fit_resample(X,y)\n",
    "\n",
    "cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "model_KNN_1_res = KNeighborsClassifier(n_neighbors=3)\n",
    "scores1 = cross_val_score(model_KNN_1_res, X_res, y_res, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "scores2 = cross_val_score(model_KNN_1_res, X_res, y_res, scoring='precision', cv=cv, n_jobs=-1)\n",
    "scores3 = cross_val_score(model_KNN_1_res, X_res, y_res, scoring='recall', cv=cv, n_jobs=-1)\n",
    "scores4 = cross_val_score(model_KNN_1_res, X_res, y_res, scoring='f1', cv=cv, n_jobs=-1)\n",
    "scores5 = cross_val_score(model_KNN_1_res, X_res, y_res, scoring='roc_auc', cv=cv, n_jobs=-1)\n",
    "print('Accuracy: %.2f' % (mean(scores1)))\n",
    "print('Precision: %.2f' % (mean(scores2)))\n",
    "print('Recall: %.2f' % (mean(scores3)))\n",
    "print('F1 Score: %.2f' % (mean(scores4)))\n",
    "print('AUC Score: %.2f' % (mean(scores5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7006af4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# roc curve for KNN model (oversampled data)\n",
    "\n",
    "pred_prob6 = model_KNN_res.predict_proba(X_test)\n",
    "fpr6, tpr6, thresh6 = roc_curve(y_test, pred_prob6[:,1], pos_label=1)\n",
    "\n",
    "# roc curve for tpr = fpr \n",
    "random_probs = [0 for i in range(len(y_test))]\n",
    "p_fpr, p_tpr, _ = roc_curve(y_test, random_probs, pos_label=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e43babe",
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_score6 = roc_auc_score(y_test, pred_prob6[:,1])\n",
    "print(auc_score6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdffea0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot roc curve (original data)\n",
    "\n",
    "plt.style.use('seaborn')\n",
    "\n",
    "\n",
    "plt.plot(tpr6, fpr6, linestyle='--',color='red', label='KNN')\n",
    "plt.plot(p_fpr, p_tpr, linestyle='--', color='blue')\n",
    "# title\n",
    "plt.title('ROC curve')\n",
    "# x label\n",
    "plt.xlabel('False Positive Rate')\n",
    "# y label\n",
    "plt.ylabel('True Positive Rate')\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.savefig(\"C:/Users/Toomas/Desktop/ITMI_Data/Tables and graphs/25_64/ML/ROC_curve_KNN_BMI30_res.pdf\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53122aa0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# a plot of roc curves of all 6 models (oversampled data)\n",
    "plt.style.use('seaborn')\n",
    "\n",
    "# plot roc curves\n",
    "plt.plot(tpr1, fpr1, linestyle='--',color='orange', label='Logistic Regression')\n",
    "plt.plot(tpr2, fpr2, linestyle='--',color='green', label='Random Forest')\n",
    "plt.plot(tpr3, fpr3, linestyle='--',color='violet', label='Support Vector Machine')\n",
    "plt.plot(tpr4, fpr4, linestyle='--',color='blue', label='Decision Tree')\n",
    "plt.plot(tpr5, fpr5, linestyle='--',color='red', label='Naive Bayes')\n",
    "plt.plot(tpr6, fpr6, linestyle='--',color='brown', label='K-Nearest Neighbor')\n",
    "\n",
    "plt.plot(p_fpr, p_tpr, linestyle='--', color='black', linewidth=3)\n",
    "# title\n",
    "plt.title('ROC curve')\n",
    "# x label\n",
    "plt.xlabel('False Positive Rate')\n",
    "# y label\n",
    "plt.ylabel('True Positive Rate')\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.savefig(\"C:/Users/Toomas/Desktop/ITMI_Data/Tables and graphs/25_64/ML/ROC_curve_all6_BMI30_res.pdf\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf5d064",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# a plot of roc curves of all 6 models / black and white\n",
    "plt.style.use('seaborn')\n",
    "\n",
    "# plot roc curves\n",
    "plt.plot(tpr1, fpr1, linestyle=':',color = 'black',label='Logistic Regression')\n",
    "plt.plot(tpr2, fpr2, linestyle='-',color='black', label='Random Forest')\n",
    "plt.plot(tpr3, fpr3, linestyle='--',color='black', label='Support Vector Machine')\n",
    "plt.plot(tpr4, fpr4, linestyle='-.',color='black', label='Decisions Tree')\n",
    "plt.plot(tpr5, fpr5, linestyle='--',color='black', linewidth=3, label='Naive Bayes')\n",
    "plt.plot(tpr6, fpr6, linestyle='-.',color='black', label='K-Nearest Neighbor')\n",
    "\n",
    "plt.plot(p_fpr, p_tpr, linestyle='--', color='black', linewidth=3)\n",
    "# title\n",
    "plt.title('ROC curve')\n",
    "# x label\n",
    "plt.xlabel('False Positive Rate')\n",
    "# y label\n",
    "plt.ylabel('True Positive Rate')\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.savefig(\"C:/Users/Toomas/Desktop/ITMI_Data/Tables and graphs/25_64/ML/ROC_curve_all6_BW_BMI30_res.pdf\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb053b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e53b42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
